{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explain and apply in R the **Permutation-Based Cluster-Mass** method proposed by [Maris and Oostenveld, 2007](https://doi.org/10.1016/j.jneumeth.2007.03.024) and developed in R by [Frossard and Renaud, 2018](https://cran.r-project.org/web/packages/permuco/vignettes/permuco_tutorial.pdf), using EEG data. Finally the **All-Resolution Inference** from [Rosenblatt et al. 2018](https://doi.org/10.1016/j.neuroimage.2018.07.060) is applied in order to compute the lower bound for the true discovery proportion inside the clusters computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages\n",
    "\n",
    "First of all, you need to install and load the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(ARIeeg): there is no package called 'ARIeeg'\n",
     "output_type": "error",
     "traceback": [
      "Error in library(ARIeeg): there is no package called 'ARIeeg'\nTraceback:\n",
      "1. library(ARIeeg)"
     ]
    }
   ],
   "source": [
    "#devtools::install_github(\"angeella/ARIeeg\")\n",
    "#devtools::install_github(\"bnicenboim/eeguana\")\n",
    "#devtools::install_github(\"jaromilfrossard/permuco\")\n",
    "library(ARIeeg)\n",
    "library(dplyr)\n",
    "library(eeguana)\n",
    "library(ggplot2)\n",
    "library(tidyr)\n",
    "library(purrr)\n",
    "library(abind)\n",
    "library(permuco4brain)\n",
    "library(hommel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The Dataset from the package ```ARIeeg``` is an **ERP experiment** composed by:\n",
    "\n",
    "- 20 Subjects,\n",
    "- 32 Channels\n",
    "- Stimuli: pictures. Conditions:\n",
    "    1. (f): fear (face)\n",
    "    2. (h): happiness (face)\n",
    "    3. (d): disgust (face)\n",
    "    4. (n): neutral (face)\n",
    "    5. (o): object\n",
    "\n",
    "We have one observation for each subject and each stimulus. You can load it using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load(system.file(\"extdata\", \"data_eeg_emotion.RData\", package = \"ARIeeg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the data as ```eeg_lst``` class object from the package ```eeguana```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utilsTOlst(data=dati)\n",
    "is_eeg_lst(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we drop off the final $5$ channels: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_to_rm <- c(\"RM\"  ,  \"EOGvo\" ,\"EOGvu\"\n",
    "                , \"EOGhl\", \"EOGhr\")\n",
    "data <- \n",
    "  data %>%\n",
    "  select(-one_of(chan_to_rm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we segment the data and select two conditions, i.e., **disgust face** and **object**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seg <- data %>%\n",
    "  eeg_segment(.description %in% c(3,5),\n",
    "              lim = c(min(dati$timings$time), max(dati$timings$time))\n",
    "  ) %>% eeg_baseline()  %>%\n",
    "  mutate(\n",
    "    condition =\n",
    "      description\n",
    "  ) %>%\n",
    "  select(-c(type,description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Some plot to understand the global mean difference between the two conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seg %>%\n",
    "  select(Fp1,Fp2, F3, F4) %>%\n",
    "  ggplot(aes(x = .time, y = .value)) +\n",
    "  geom_line(aes(group = condition))  +\n",
    "  stat_summary(\n",
    "    fun = \"mean\", geom = \"line\", alpha = 1, size = 1.5,\n",
    "    aes(color = condition),show.legend = TRUE\n",
    "  ) +\n",
    "  facet_wrap(~.key) +\n",
    "  geom_vline(xintercept = 0, linetype = \"dashed\") +\n",
    "  geom_vline(xintercept = .17, linetype = \"dotted\") +\n",
    "  theme(legend.position = \"bottom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "## Multiple testing problem?\n",
    "\n",
    "The aim is to test if the difference of brain signal during the two conditions is different from $0$ for each time points, i.e., $500$, and for each channel, i.e., $27$. Therefore, we have $500 \\cdot 27$ statistical tests to perform at group-level, so considering the **random subject effect**. The multiple testing problem is then obvious, and correction methods as Bonferroni or similar don't capture the time-spatial correlation structure of the statistical tests, the cluster mass method, proposed by [Maris and Oostenveld, 2007](https://doi.org/10.1016/j.jneumeth.2007.03.024), is then used. It is based on **permutation theory**, and it gains some power respect to other procedure correcting at level of spatial-temporal cluster instead of at level of single tests. It is similar to the cluster mass in the fMRI framework, but in this case, the *voxels*, i.e., the single object of the analysis, are expressed in terms of combination time-points/channels. The method is then able to gain some power respect to some traditional conservative FWER correction method exploiting the spatial-temporal structure of the data.\n",
    "\n",
    "## Repeated Measures Anova Model\n",
    "\n",
    "The cluster mass method is based on the **Repeated Measures Anova**, i.e.,\n",
    "\n",
    "$$\n",
    "y = \\mathbb{1}_{N \\times 1} \\mu +  \\eta X_{\\eta} + \\pi X_{\\pi} +  \\eta \\pi X_{\\eta \\pi} + \\epsilon\n",
    "$$\n",
    "\n",
    "where $1_{N \\times 1}$ is a matrix with ones and\n",
    "\n",
    "  1. $\\mu$ is the **intercept**;\n",
    "  2. $y \\in \\mathbb{R}^{N \\times 1}$ is the response variables, i.e., the **signal**, in our case $N = n_{subj} \\times n_{stimuli} = 40$;\n",
    "  3. $X^{\\eta} \\in \\mathbb{R}^{N \\times n_{stimuli}}$ is the **design matrix** describing the **fixed effect** regarding the stimuli, and $\\eta \\in \\mathbb{R}^{n_{stimuli} \\times 1}$ the corresponding parameter of interest;\n",
    "  4. $X_{\\pi} \\in \\mathbb{R}^{N \\times n_{subj}}$ is the **design matrix** describing the **random effect** regarding the subjects, and $\\pi \\in \\mathbb{R}^{n_{subj} \\times 1}$ the corresponding parameter.\n",
    "  5. $X^{\\eta \\pi}$ is the **design matrix** describing the **interaction effects** between subjects and conditions;\n",
    "  6. $\\epsilon \\in \\mathbb{R}^{N \\times 1}$ is the **error term** with $0$ mean and variance $\\sigma^2 I_N$.\n",
    "\n",
    "Therefore, $y \\sim (\\mathbb{1}\\mu + X^{\\eta} \\eta, \\Sigma)$, $\\pi \\sim (0, \\sigma^2_{\\pi} I_{nsubj})$ and $\\eta \\pi \\sim (0,\\text{cov}(\\eta \\pi))$.\n",
    "\n",
    "We want to make inference on $\\eta$, such that $H_0: \\eta = 0$ vs $H_1: \\eta \\ne 0$. We do that using the **F statistic**, i.e.,\n",
    "\n",
    "$$\n",
    "F = \\dfrac{y^\\top H_{X^{\\eta}} y / (n_{stimuli} - 1)}{ y^\\top H_{X^{\\eta \\pi}}y/(n_{stimuli} -1)(n_{subj} -1)} \n",
    "$$\n",
    "where $H_{X}$ is the **projection matrix**, i.e., $H_{X} = X(X^\\top X)^{-1} X^\\top$. In order to compute this test, we use an alternative definition of $F$ based on the residuals:\n",
    "\n",
    "$$\n",
    "F = \\dfrac{r^\\top H_{X^{\\eta}} r / (n_{stimuli} - 1)}{ r^\\top H_{X^{\\eta \\pi}}r/(n_{stimuli} -1)(n_{subj} -1)} \n",
    "$$\n",
    "\n",
    "where $r = (H_{X^{\\eta}} + H_{X^{\\eta\\pi}})y$. For further details, see [Kherad Pajouh and Renaud, 2014](https://link.springer.com/article/10.1007/s00362-014-0617-3).\n",
    "\n",
    "So, let the group of permutation, including the identity transformation, $\\mathcal{P}$, we use $r^\\star = P r$, where $P \\in \\mathcal{P}$ to compute the null distribution of our test, i.e., $\\mathcal{R}$, and then the p-value, i.e.,\n",
    "\n",
    "$$\n",
    "\\text{p-value} = \\dfrac{1}{B} \\sum_{r^\\star_b \\in \\mathcal{R}} \\mathbb{I}(|r^\\star_b| \\ge |r|)\n",
    "$$\n",
    "\n",
    "if the two-tailed is considered.\n",
    "\n",
    "We have this model for each time point $t \\in \\{1, \\dots, 500\\}$ and each channel, so finally we will have $n_{\\text{time-points}} \\times n_{\\text{channels}}$ statistical tests/p-values (raw).\n",
    "\n",
    "## Spatio-temporal Cluster mass \n",
    "\n",
    "Then, we need to construct the **spatial-temporal clusters** in order to correct the raw p-values for the FWER. In this case, we will use the theory of graph, where the vertices represent the channels, and the edges represent the **adjacency** relationship. The adjacency must be defined using prior information, therefore the three-dimensional Euclidean distance between channels is used. Two channels are defined adjacent if their Euclidean distance is less than a threshold $\\delta$, where $\\delta$ is the smallest euclidean distance that produces a connected graph. This is due to the fact that a connected graph implies no disconnected sub-graph. Having sub-graphs implies that some tests cannot, by design, be in the same cluster, which is not a useful assumption for this analysis. ([Frossard and Renaud, 2018](https://cran.r-project.org/web/packages/permuco/vignettes/permuco_tutorial.pdf); [Frossard, 2019](10.13097/archive-ouverte/unige:125617)).\n",
    "\n",
    "Then, having the spatial adjacency definition, we need to define the temporal one. We reproduce this graph $n_{\\text{time-points}}$ times, the edges between all pairs of two vertices (tests) are associated with the same electrode when they are temporally adjacent. The final graph has a total of vertices equals to the number of tests ($n_{\\text{channels}} \\times n_{\\text{time-points}}$). The following figure represents the case of $64$ channels and $3$ temporal measures:\n",
    "\n",
    "![Example of graph of adjacency from [Frossard, 2019](10.13097/archive-ouverte/unige:125617)](Image/cluster.JPG)\n",
    "\n",
    "We then delete all the vertices in which statistics are below a threshold, e.g., the $95$ percentile of the null distribution of the $F$ statistics. So, we have a new graph composed of **multiple connected components**. Then, each connected component is interpreted as a spatiotemporal cluster. Finally, for each connected component, we compute the cluster-mass statistic using the sum (or sum of squares) of statistics of that particular connected component.\n",
    "\n",
    "The cluster-mass null distribution is computed by permutations while maintaining spatio-temporal correlations among tests. Permutations must be performed without changing the position of electrodes nor mixing time-points. Concretely, after transforming the responses using the permutation method in [Kherad Pajouh and Renaud, 2014](https://link.springer.com/article/10.1007/s00362-014-0617-3), they are sorted in a three-dimensional array. It has the design (subjects $\\times$ stimuli) in the first dimension, time in the second one and electrodes in the third one. Then, only the first dimension is permuted to create a re-sampled response (or 3D array). Doing so, it does not reorder time-points, neither electrodes, therefore, the spatiotemporal correlations are maintained within each permuted sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permuco4brain\n",
    "\n",
    "In R, all of this is possible thanks to the permuco and permuco4brain packages developed by [Frossard and Renaud, 2018](https://cran.r-project.org/web/packages/permuco/vignettes/permuco_tutorial.pdf).\n",
    "\n",
    "1. Construct the $y$. We need to construct the three-dimensional **signal array**, having dimensions $40 \\times 500 \\times 27$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal <- \n",
    "    data_seg%>%\n",
    "    signal_tbl()%>%\n",
    "    group_by(.id)%>%\n",
    "    nest()%>%\n",
    "    mutate(data = map(data,~as.matrix(.x[-1])))%>%\n",
    "    pull(data)%>%\n",
    "    invoke(abind,.,along = 3)%>%\n",
    "    aperm(c(3,1,2))\n",
    "\n",
    "dim(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Construct the $X_{\\eta \\pi}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design <- \n",
    "  segments_tbl(data_seg)%>%\n",
    "  select(.subj, condition)\n",
    "dim(design)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Construct the **graph**, using $\\delta = 53mm$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph <- position_to_graph(channels_tbl(data_seg), name = .channel, delta = 53,\n",
    "                             x = .x, y = .y, z = .z)\n",
    "plot(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Define the **repeated measures ANOVA formula**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula <- signal ~ condition + Error(.subj/(condition))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the main function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model <- permuco4brain::brainperm(formula = formula,\n",
    "                                  data = design,\n",
    "                                  graph = graph,\n",
    "                                  np = 5000,\n",
    "                                  multcomp = \"clustermass\",\n",
    "                                  return_distribution = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where np indicates the number of permutation.\n",
    "\n",
    "Then, we can analyze the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have only one significant cluster (32), with p-value equals to $0.0002$ and cluster mass equals to $56102.363567$. It is composed by $27$ channels (the total set), with main channels P8. You can see in details the components of this cluster in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(model$multiple_comparison$condition$clustermass$cluster$membership[which(as.vector(model$multiple_comparison$condition$clustermass$cluster$membership)==11)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the significant cluster (in red) at fixed time points (e.g. 160) using plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model, samples = 160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the significant cluster over time and over channels using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the significant clusters are represented in a colour-scale and the non-significant one in grey. The white pixels are tests which statistic are below the threshold.\n",
    "\n",
    "# ARI in EEG cluster mass\n",
    "\n",
    "However, our significant cluster (11) says only that at least one combination channels/time-points is different from $0$, we don't know how many combinations are significant (**spatial specificity paradox**). So, we can apply ARI to understand the lower bound of the number of true discovery proportion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARIeeg(model = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have at least $16.58\\%$ truly active component in the cluster $32$.\n",
    "\n",
    "# References\n",
    "\n",
    " - Maris, E., & Oostenveld, R. (2007). Nonparametric statistical testing of EEG-and MEG-data. Journal of neuroscience methods, 164(1), 177-190.\n",
    "\n",
    " - Kherad-Pajouh, S., & Renaud, O. (2015). A general permutation approach for analyzing repeated measures ANOVA and mixed-model designs. Statistical Papers, 56(4), 947-967.\n",
    " \n",
    " - Frossard, J. (2019). Permutation tests and multiple comparisons in the linear models and mixed linear models, with extension to experiments using electroencephalography. DOI: 10.13097/archive-ouverte/unige:125617.\n",
    " \n",
    " - Frossard, J. & O. Renaud (2018). Permuco: Permutation Tests for Regression, (Repeated Measures) ANOVA/ANCOVA and Comparison of Signals. R Packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
